{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "302Try.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OzOmwCTQnS4e",
        "outputId": "d92a81dc-6532-47cf-a0b5-d5ef3e0c9c90"
      },
      "source": [
        "#Connecting to my google drive for accessing dataset\n",
        "import os\n",
        "from google.colab import drive\n",
        "MOUNTPOINT = '/content/gdrive'\n",
        "DATADIR = os.path.join(MOUNTPOINT, 'My Drive', 'Project')\n",
        "path=os.path.join(DATADIR, 'undata.csv')\n",
        "drive.mount(MOUNTPOINT,force_remount=True)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbWviPe6obpW"
      },
      "source": [
        "#importing common python libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import string\n",
        "import re\n",
        "\n",
        "#importing required libraries from nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "\n",
        "#importing required libraries from sklearn\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "#Hiding all the unneccesary warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "S7zO_2eDoihq",
        "outputId": "df1e8d29-5c49-4af9-fa45-85105c57cf17"
      },
      "source": [
        "#Loading UN sustainable development goals dataset\n",
        "df = pd.read_csv(path, header=0,index_col=0)\n",
        "df.head()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text_id</th>\n",
              "      <th>text</th>\n",
              "      <th>sdg</th>\n",
              "      <th>labels_negative</th>\n",
              "      <th>labels_positive</th>\n",
              "      <th>agreement</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>doi</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>10.6027/9789289342698-7-en</th>\n",
              "      <td>00021941702cd84171ff33962197ca1f</td>\n",
              "      <td>From a gender perspective, Paulgaard points ou...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>0.750000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10.18356/eca72908-en</th>\n",
              "      <td>00028349a7f9b2485ff344ae44ccfd6b</td>\n",
              "      <td>Labour legislation regulates maximum working h...</td>\n",
              "      <td>11</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10.1787/9789264289062-4-en</th>\n",
              "      <td>0004eb64f96e1620cd852603d9cbe4d4</td>\n",
              "      <td>The average figure also masks large difference...</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>0.714286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10.1787/5k9b7bn5qzvd-en</th>\n",
              "      <td>0006a887475ccfa5a7f5f51d4ac83d02</td>\n",
              "      <td>The extent to which they are akin to corruptio...</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10.1787/9789264258211-6-en</th>\n",
              "      <td>0006d6e7593776abbdf4a6f985ea6d95</td>\n",
              "      <td>A region reporting a higher rate will not earn...</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                     text_id  ... agreement\n",
              "doi                                                           ...          \n",
              "10.6027/9789289342698-7-en  00021941702cd84171ff33962197ca1f  ...  0.750000\n",
              "10.18356/eca72908-en        00028349a7f9b2485ff344ae44ccfd6b  ...  0.333333\n",
              "10.1787/9789264289062-4-en  0004eb64f96e1620cd852603d9cbe4d4  ...  0.714286\n",
              "10.1787/5k9b7bn5qzvd-en     0006a887475ccfa5a7f5f51d4ac83d02  ...  0.333333\n",
              "10.1787/9789264258211-6-en  0006d6e7593776abbdf4a6f985ea6d95  ...  0.000000\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJ2O-ShrOrrq"
      },
      "source": [
        "The dataset contains so many entries for which value of negative labels is higher than value of positive labels. Even the agreement value is very less. Such entries are good for training the model as they actually decrease the accuracy of the model. So we are going to take only those entries where agreement value is at least 0.6 and positive labels value > negative labels value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "id": "piJK2U6Blq1X",
        "outputId": "e788b770-3a62-46b0-83f7-5d8e530e654c"
      },
      "source": [
        "#Keeping only the texts whose suggested sdg labels is accepted and the agreement score is at least 0.6\n",
        "print('Shape before:', df.shape)\n",
        "df = df.query('agreement >= .6 and labels_positive > labels_negative').copy()\n",
        "print('Shape after :', df.shape)\n",
        "display(df.head())"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape before: (17233, 6)\n",
            "Shape after : (17233, 6)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text_id</th>\n",
              "      <th>text</th>\n",
              "      <th>sdg</th>\n",
              "      <th>labels_negative</th>\n",
              "      <th>labels_positive</th>\n",
              "      <th>agreement</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>doi</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>10.6027/9789289342698-7-en</th>\n",
              "      <td>00021941702cd84171ff33962197ca1f</td>\n",
              "      <td>From a gender perspective, Paulgaard points ou...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>0.750000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10.1787/9789264289062-4-en</th>\n",
              "      <td>0004eb64f96e1620cd852603d9cbe4d4</td>\n",
              "      <td>The average figure also masks large difference...</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>0.714286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10.1787/9789264117563-8-en</th>\n",
              "      <td>000bfb17e9f3a00d4515ab59c5c487e7</td>\n",
              "      <td>The Israel Oceanographic and Limnological Rese...</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10.18356/805b1ae4-en</th>\n",
              "      <td>001180f5dd9a821e651ed51e30d0cf8c</td>\n",
              "      <td>Previous chapters have discussed ways to make ...</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10.1787/9789264310278-en</th>\n",
              "      <td>001f1aee4013cb098da17a979c38bc57</td>\n",
              "      <td>Prescription rates appear to be higher where l...</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                     text_id  ... agreement\n",
              "doi                                                           ...          \n",
              "10.6027/9789289342698-7-en  00021941702cd84171ff33962197ca1f  ...  0.750000\n",
              "10.1787/9789264289062-4-en  0004eb64f96e1620cd852603d9cbe4d4  ...  0.714286\n",
              "10.1787/9789264117563-8-en  000bfb17e9f3a00d4515ab59c5c487e7  ...  1.000000\n",
              "10.18356/805b1ae4-en        001180f5dd9a821e651ed51e30d0cf8c  ...  1.000000\n",
              "10.1787/9789264310278-en    001f1aee4013cb098da17a979c38bc57  ...  1.000000\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UNbmpbpypBmi",
        "outputId": "4107215f-c877-4701-ba33-8264e7f1a0ae"
      },
      "source": [
        "#Checking general information about the dataset\n",
        "df.info()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 17233 entries, 10.6027/9789289342698-7-en to 10.18356/39dd1e2e-en\n",
            "Data columns (total 6 columns):\n",
            " #   Column           Non-Null Count  Dtype  \n",
            "---  ------           --------------  -----  \n",
            " 0   text_id          17233 non-null  object \n",
            " 1   text             17233 non-null  object \n",
            " 2   sdg              17233 non-null  int64  \n",
            " 3   labels_negative  17233 non-null  int64  \n",
            " 4   labels_positive  17233 non-null  int64  \n",
            " 5   agreement        17233 non-null  float64\n",
            "dtypes: float64(1), int64(3), object(2)\n",
            "memory usage: 942.4+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qIbWQLD_QAJm"
      },
      "source": [
        "Since all the columns have equal number of non-null values, we are good to go ahead, but we do not need all the columns for modeling, in the next step we will be taking only those columns that are required."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "f7S6yvtgpItp",
        "outputId": "29d77b6d-ed41-4afe-d3a8-5d0fc26146c9"
      },
      "source": [
        "#Taking only two columns - sdg and text\n",
        "text_df = df[['sdg', 'text']]\n",
        "text_df.head()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sdg</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>doi</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>10.6027/9789289342698-7-en</th>\n",
              "      <td>5</td>\n",
              "      <td>From a gender perspective, Paulgaard points ou...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10.1787/9789264289062-4-en</th>\n",
              "      <td>3</td>\n",
              "      <td>The average figure also masks large difference...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10.1787/9789264117563-8-en</th>\n",
              "      <td>6</td>\n",
              "      <td>The Israel Oceanographic and Limnological Rese...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10.18356/805b1ae4-en</th>\n",
              "      <td>2</td>\n",
              "      <td>Previous chapters have discussed ways to make ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10.1787/9789264310278-en</th>\n",
              "      <td>8</td>\n",
              "      <td>Prescription rates appear to be higher where l...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                            sdg                                               text\n",
              "doi                                                                               \n",
              "10.6027/9789289342698-7-en    5  From a gender perspective, Paulgaard points ou...\n",
              "10.1787/9789264289062-4-en    3  The average figure also masks large difference...\n",
              "10.1787/9789264117563-8-en    6  The Israel Oceanographic and Limnological Rese...\n",
              "10.18356/805b1ae4-en          2  Previous chapters have discussed ways to make ...\n",
              "10.1787/9789264310278-en      8  Prescription rates appear to be higher where l..."
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "OmKM_Qi43SpZ",
        "outputId": "6336d4ef-ef81-4556-f954-0c0217ef6839"
      },
      "source": [
        "#Printing a random entry from text column.\n",
        "text_df['text'][3]"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Previous chapters have discussed ways to make food systems more supportive of food security and better nutrition. Nutrition-sensitive food systems can give consumers better options, but ultimately it is consumers who choose what they eat. What consumers choose to eat influences their own nutritional outcomes and sends signals back through the food system - to retailers, processors and producers - that shape both what is produced and how sustainably it is produced.'"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kCYQTGqM3bON"
      },
      "source": [
        "#Above we saw that text is an object type column. So we want to change it to string type for future usage.\n",
        "text_df['text'] = text_df['text'].astype(str)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZ_aJKWH42Vn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0d0cc2c-9065-4928-bd2a-c8cd8635220a"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "stop = stopwords.words('english')\n",
        "porter = PorterStemmer()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QZSfARz5o01"
      },
      "source": [
        "#Function for removing punctuations from the texts.\n",
        "def remove_punctuation(description):\n",
        "    \"\"\"The function to remove punctuation\"\"\"\n",
        "    table = str.maketrans('', '', string.punctuation)\n",
        "    return description.translate(table)\n",
        "\n",
        "#Function for removing the stopwords from the texts.\n",
        "def remove_stopwords(text):\n",
        "    \"\"\"The function to removing stopwords\"\"\"\n",
        "    text = [word.lower() for word in text.split() if word.lower() not in stop]\n",
        "    return \" \".join(text)\n",
        "\n",
        "#Function for stemming the words to their root word.\n",
        "def stemmer(stem_text):\n",
        "    \"\"\"The function to apply stemming\"\"\"\n",
        "    stem_text = [porter.stem(word) for word in stem_text.split()]\n",
        "    return \" \".join(stem_text)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNwRiGJ65vEE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "1186dc84-484f-4dc8-d752-d84ccff422b6"
      },
      "source": [
        "#Applying above functions on text column \n",
        "text_df['text'] = text_df['text'].apply(remove_punctuation)\n",
        "text_df['text'] = text_df['text'].apply(remove_stopwords)\n",
        "text_df['text'] = text_df['text'].apply(stemmer)\n",
        "text_df.head()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sdg</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>doi</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>10.6027/9789289342698-7-en</th>\n",
              "      <td>5</td>\n",
              "      <td>gender perspect paulgaard point labour market ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10.1787/9789264289062-4-en</th>\n",
              "      <td>3</td>\n",
              "      <td>averag figur also mask larg differ across regi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10.1787/9789264117563-8-en</th>\n",
              "      <td>6</td>\n",
              "      <td>israel oceanograph limnolog research station m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10.18356/805b1ae4-en</th>\n",
              "      <td>2</td>\n",
              "      <td>previou chapter discuss way make food system s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10.1787/9789264310278-en</th>\n",
              "      <td>8</td>\n",
              "      <td>prescript rate appear higher labour forc parti...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                            sdg                                               text\n",
              "doi                                                                               \n",
              "10.6027/9789289342698-7-en    5  gender perspect paulgaard point labour market ...\n",
              "10.1787/9789264289062-4-en    3  averag figur also mask larg differ across regi...\n",
              "10.1787/9789264117563-8-en    6  israel oceanograph limnolog research station m...\n",
              "10.18356/805b1ae4-en          2  previou chapter discuss way make food system s...\n",
              "10.1787/9789264310278-en      8  prescript rate appear higher labour forc parti..."
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "Pc3-knh47CAD",
        "outputId": "00a02405-c39f-4c72-e572-6b65729b0267"
      },
      "source": [
        "#Let's see a random entry from the text column after the transformation.\n",
        "text_df['text'][1]"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'averag figur also mask larg differ across region kazakhstan number annual contact rang 20 astana 97 mangystau part popul like limit access primari care addit poor coverag outpati prescript medicin limit effect appeal care phc level'"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6OkJNpBFQyy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "daadb793-0ed2-4faa-85bb-d44f022104f0"
      },
      "source": [
        "#Splitting the data into train and test sets\n",
        "X = text_df['text']\n",
        "y = text_df['sdg']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state = 0)\n",
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((12924,), (4309,), (12924,), (4309,))"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwpIl-WEG958",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9807fc0a-8e42-484e-da1d-9fc28c6590ee"
      },
      "source": [
        "#Logistic Regression model\n",
        "model_log = Pipeline([('vect', CountVectorizer(min_df=5, ngram_range=(1,2))),\n",
        "                      ('tfidf', TfidfTransformer()),\n",
        "                      ('model',LogisticRegression()),\n",
        "                     ])\n",
        "\n",
        "model_log.fit(X_train, y_train)\n",
        "\n",
        "ytest = np.array(y_test)\n",
        "pred = model_log.predict(X_test)\n",
        "print('accuracy %s' % accuracy_score(pred, y_test))\n",
        "print(classification_report(ytest, pred))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy 0.872360176375029\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.83      0.85      0.84       296\n",
            "           2       0.82      0.82      0.82       199\n",
            "           3       0.89      0.94      0.92       434\n",
            "           4       0.93      0.96      0.94       603\n",
            "           5       0.92      0.97      0.95       558\n",
            "           6       0.91      0.93      0.92       346\n",
            "           7       0.87      0.94      0.90       395\n",
            "           8       0.72      0.70      0.71       214\n",
            "           9       0.71      0.75      0.73       165\n",
            "          10       0.77      0.37      0.50       117\n",
            "          11       0.84      0.87      0.86       300\n",
            "          12       0.77      0.34      0.47        71\n",
            "          13       0.87      0.86      0.87       296\n",
            "          14       0.94      0.90      0.92       179\n",
            "          15       0.90      0.76      0.83       136\n",
            "\n",
            "    accuracy                           0.87      4309\n",
            "   macro avg       0.85      0.80      0.81      4309\n",
            "weighted avg       0.87      0.87      0.87      4309\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4UeCxBvIfHR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "102f8dcb-ccd7-4c1a-da99-ae4bb09801e9"
      },
      "source": [
        "#SGD Classifier model\n",
        "pipeline = Pipeline(\n",
        "            [\n",
        "                ('vect', CountVectorizer()),\n",
        "                ('tfidf', TfidfTransformer()),\n",
        "                ('clf', SGDClassifier(\n",
        "                    loss='modified_huber',\n",
        "                    penalty='l2',\n",
        "                    alpha=1e-3,\n",
        "                    random_state=42,\n",
        "                    max_iter=100,\n",
        "                    tol=None,\n",
        "                )),\n",
        "            ]\n",
        "        )\n",
        "classifier = pipeline.fit(X_train, y_train)\n",
        "ytest = np.array(y_test)\n",
        "y_pred = classifier.predict(X_test)\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "print(classification_report(ytest, y_pred))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy 0.875609190067301\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.83      0.85      0.84       296\n",
            "           2       0.81      0.84      0.82       199\n",
            "           3       0.90      0.95      0.93       434\n",
            "           4       0.92      0.97      0.94       603\n",
            "           5       0.91      0.97      0.94       558\n",
            "           6       0.91      0.94      0.92       346\n",
            "           7       0.87      0.93      0.90       395\n",
            "           8       0.72      0.67      0.69       214\n",
            "           9       0.77      0.73      0.75       165\n",
            "          10       0.76      0.38      0.51       117\n",
            "          11       0.88      0.87      0.87       300\n",
            "          12       0.77      0.42      0.55        71\n",
            "          13       0.89      0.85      0.87       296\n",
            "          14       0.94      0.94      0.94       179\n",
            "          15       0.87      0.78      0.82       136\n",
            "\n",
            "    accuracy                           0.88      4309\n",
            "   macro avg       0.85      0.81      0.82      4309\n",
            "weighted avg       0.87      0.88      0.87      4309\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvaU1sDOItRL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "343b9b88-507b-425c-935d-e5af9fbc70a6"
      },
      "source": [
        "#Multinomial Naive Bayes model\n",
        "nbc = Pipeline([('vect', CountVectorizer(min_df=5, ngram_range=(1,2))),\n",
        "               ('tfidf', TfidfTransformer()),\n",
        "               ('model',MultinomialNB()),\n",
        "               ])\n",
        "\n",
        "nbc.fit(X_train, y_train)\n",
        "ytest = np.array(y_test)\n",
        "pred_y = nbc.predict(X_test)\n",
        "print('accuracy %s' % accuracy_score(pred_y, y_test))\n",
        "print(classification_report(ytest, pred_y))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy 0.7203527500580181\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.84      0.66      0.74       296\n",
            "           2       0.93      0.47      0.62       199\n",
            "           3       0.85      0.93      0.89       434\n",
            "           4       0.71      0.97      0.82       603\n",
            "           5       0.55      0.99      0.71       558\n",
            "           6       0.77      0.87      0.82       346\n",
            "           7       0.61      0.95      0.74       395\n",
            "           8       0.83      0.02      0.05       214\n",
            "           9       1.00      0.06      0.11       165\n",
            "          10       0.00      0.00      0.00       117\n",
            "          11       0.86      0.71      0.78       300\n",
            "          12       0.00      0.00      0.00        71\n",
            "          13       0.88      0.77      0.82       296\n",
            "          14       0.96      0.60      0.74       179\n",
            "          15       1.00      0.24      0.38       136\n",
            "\n",
            "    accuracy                           0.72      4309\n",
            "   macro avg       0.72      0.55      0.55      4309\n",
            "weighted avg       0.75      0.72      0.67      4309\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5umlU7G3I6dy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5017c491-c208-4902-a4e1-bc2b3b1ca92a"
      },
      "source": [
        "#Random Forest Classifier\n",
        "rf = Pipeline([('vect', CountVectorizer(min_df=5, ngram_range=(1,2))),\n",
        "               ('tfidf', TfidfTransformer()),\n",
        "               ('rf', RandomForestClassifier(n_estimators=50)),\n",
        "               ])\n",
        "\n",
        "rf.fit(X_train, y_train)\n",
        "ytest = np.array(y_test)\n",
        "preds = rf.predict(X_test)\n",
        "print('accuracy %s' % accuracy_score(preds, y_test))\n",
        "print(classification_report(ytest, preds))"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy 0.8275702019029937\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.79      0.82      0.81       296\n",
            "           2       0.75      0.80      0.78       199\n",
            "           3       0.89      0.94      0.91       434\n",
            "           4       0.86      0.96      0.90       603\n",
            "           5       0.87      0.96      0.91       558\n",
            "           6       0.85      0.92      0.88       346\n",
            "           7       0.79      0.93      0.85       395\n",
            "           8       0.63      0.50      0.55       214\n",
            "           9       0.71      0.53      0.61       165\n",
            "          10       0.76      0.27      0.40       117\n",
            "          11       0.80      0.76      0.78       300\n",
            "          12       0.92      0.15      0.27        71\n",
            "          13       0.83      0.82      0.83       296\n",
            "          14       0.91      0.89      0.90       179\n",
            "          15       0.89      0.66      0.76       136\n",
            "\n",
            "    accuracy                           0.83      4309\n",
            "   macro avg       0.82      0.73      0.74      4309\n",
            "weighted avg       0.82      0.83      0.82      4309\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBq4og8zJWC-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d83e7f8d-c84d-4685-8e66-17f9144e198f"
      },
      "source": [
        "#Gradient Boosting Classifier\n",
        "model_gb = Pipeline([('vect', CountVectorizer(min_df=5, ngram_range=(1,2))),\n",
        "                    ('tfidf', TfidfTransformer()),\n",
        "                    ('gb', GradientBoostingClassifier(n_estimators=50)),\n",
        "                    ])\n",
        "\n",
        "model_gb.fit(X_train, y_train)\n",
        "ytest = np.array(y_test)\n",
        "predicted = model_gb.predict(X_test)\n",
        "print('accuracy %s' % accuracy_score(predicted, y_test))\n",
        "print(classification_report(ytest, predicted))"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy 0.8410304014852634\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.81      0.79      0.80       296\n",
            "           2       0.77      0.81      0.79       199\n",
            "           3       0.77      0.91      0.84       434\n",
            "           4       0.93      0.94      0.93       603\n",
            "           5       0.92      0.95      0.94       558\n",
            "           6       0.87      0.92      0.90       346\n",
            "           7       0.88      0.90      0.89       395\n",
            "           8       0.65      0.65      0.65       214\n",
            "           9       0.72      0.65      0.68       165\n",
            "          10       0.56      0.38      0.46       117\n",
            "          11       0.84      0.77      0.81       300\n",
            "          12       0.58      0.44      0.50        71\n",
            "          13       0.87      0.84      0.86       296\n",
            "          14       0.92      0.88      0.90       179\n",
            "          15       0.86      0.75      0.80       136\n",
            "\n",
            "    accuracy                           0.84      4309\n",
            "   macro avg       0.80      0.77      0.78      4309\n",
            "weighted avg       0.84      0.84      0.84      4309\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YoW9r7vPLKS7"
      },
      "source": [
        "#Calculating accuracy of all the models \n",
        "log_acc = accuracy_score(pred, y_test)\n",
        "svm_acc = accuracy_score(y_pred, y_test)\n",
        "nb_acc = accuracy_score(pred_y, y_test)\n",
        "rf_acc = accuracy_score(preds, y_test)\n",
        "gb_acc = accuracy_score(predicted, y_test)"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "v_yj2ylILWuy",
        "outputId": "0bf86519-7740-45db-a491-adb0d5572185"
      },
      "source": [
        "#Creating a new dataframe containing all the model names and their corresponding accuracies.\n",
        "models = pd.DataFrame({\n",
        "                      'Model': ['Logistic Regression', 'SGD Classifier', 'Naive Bayes', 'Random Forest', 'Gradient Boosting', ],\n",
        "                      'Score': [log_acc, svm_acc, nb_acc, rf_acc, gb_acc]})\n",
        "models.sort_values(by='Score', ascending=False)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>SGD Classifier</td>\n",
              "      <td>0.875609</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Logistic Regression</td>\n",
              "      <td>0.872360</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Gradient Boosting</td>\n",
              "      <td>0.841030</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Random Forest</td>\n",
              "      <td>0.827570</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Naive Bayes</td>\n",
              "      <td>0.720353</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 Model     Score\n",
              "1       SGD Classifier  0.875609\n",
              "0  Logistic Regression  0.872360\n",
              "4    Gradient Boosting  0.841030\n",
              "3        Random Forest  0.827570\n",
              "2          Naive Bayes  0.720353"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjW91ludYKvq"
      },
      "source": [
        "From the above table we can see that SGD Classifier gives the highest accuracy for UN data, so we will be using SGD classifier for the final modeling."
      ]
    }
  ]
}